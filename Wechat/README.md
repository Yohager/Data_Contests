#### 2021年微信大数据挑战赛

##### 基本情况

第一次尝试搞一下比赛玩玩，倒在了初赛

初赛a榜排名：大概是400/1000左右，b榜：256/463

相当于划水了一次，基本就魔改了一下大佬提供的baseline

简单记录一下

src文件夹下的文件包括：

`deepfm.py`和`deepfm_model.py` deepfm的baseline，我自己最高处理到0.649，队友后期使用nn模型调到了0.655

`keywords_tags.ipynb` 用于处理keyword和tag数据

`lightgbm_baseline.py` 树模型的baseline文件（0.64左右）

`lightgbm_baseline_tag.py`  魔改的树模型baseline的文件，单模单折调到了0.655，b榜的测试数据单模多折调整到0.656

##### 特征工程

主要用的特征是：id特征，滑动窗口的统计特征，tag特征(multi-hot)，embedding的降维特征（512维使用pca降维到64维），user的latent特征

最终的lgb模型的特征维度为593维：在`all_features.txt`文件中给出滑动窗口的特征，embedding降维，user隐向量特征等绝大部分特征

##### 训练方式

我主要处理的lgb的模型，队友处理的nn的模型，个人感觉lgb的效果主要来自于一些新的构建的特征，nn据说使用6个id特征可以调到0.66, 不知道真假，等大佬开源之后学习一下，在训练的时候发现lgb的模型在做read_comment和like这两个模型时结果不如特征更少的nn模型，但是后两个模型比nn更好一些。

训练主要是用的单模单折的方式，offline train使用的前13天的数据训练，第14天的数据验证，基本不用userid和feedid的组合特征线上和线下的结果差距不大。

后期采用了多折的策略，我使用的多折的策略是：采用1-10天，1-11天，1-12天，1-13天以及1-14天的数据分别训练模型然后取了平均值。b榜的结果来自于这个训练方式。

##### 收获和不足

收获还是挺多的，首先第一个熟悉了不少pandas的常规操作，看别人的baseline学习到了不少的处理数据时的一些常规操作和骚操作，还是挺有意思的；第二个做组合特征，以前上一些统计课程的时候没有用到过这些操作，如何从有限的数据中提取一些新的特征，以及滑动窗口处理这些带有时序的数据的统计特征；以及什么情况下会出现数据泄露数据穿越；第三个简单了解了一下做这种预测的树模型和nn模型，大概是主要有哪些模型，以及怎么用这些模型进行预测。

不足的地方，其实主要就是有挺多没做好的地方，比如说如何做一些新特征，如何调整一些使用到的模型，另外还有一个很重要的问题，一定不能偷懒，特别是做出来的模型，结果等等的保存工作以及命名工作，前期没存好，后期就很恼火，因为很容易忘记这个结果或者模型使用到了哪些特征以及模型对应的一些参数，这个问题还是挺重要的，因为这算是一个需要养成的有条理的习惯，对于做这类数据竞赛还是很有帮助的。

